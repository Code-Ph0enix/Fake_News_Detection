# ACTUAL GOOGLE COLAB CODE PUT TOGETHER #

pip install pandas scikit-learn nltk
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

# Step 1: Load dataset
df = pd.read_csv('Fake.csv')  # replace with your dataset

# Step 2: Data Preprocessing
df = df[['text', 'label']]  # Ensure only necessary columns
df['label'] = df['label'].apply(lambda x: 1 if x == 'fake' else 0)  # Make sure labels are 0 or 1

# Split data into train and test
X = df['text']
y = df['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 3: Define vectorizer and models
stop_words = set(stopwords.words('english'))

# TF-IDF Vectorizer
vectorizer = TfidfVectorizer(stop_words=stop_words, max_df=0.95, min_df=2)

# Model 1: Decision Tree
dt_model = make_pipeline(vectorizer, DecisionTreeClassifier(random_state=42))

# Model 2: Naive Bayes
nb_model = make_pipeline(vectorizer, MultinomialNB())

# Model 3: Logistic Regression
lr_model = make_pipeline(vectorizer, LogisticRegression(random_state=42))

# Model 4: Random Forest
rf_model = make_pipeline(vectorizer, RandomForestClassifier(random_state=42))

# Model 5: Gradient Boosting
gb_model = make_pipeline(vectorizer, GradientBoostingClassifier(random_state=42))

# Model 6: SVM
svm_model = make_pipeline(vectorizer, SVC(kernel='linear', random_state=42))

# Step 4: Train and Evaluate models
models = {
    "Decision Tree": dt_model,
    "Naive Bayes": nb_model,
    "Logistic Regression": lr_model,
    "Random Forest": rf_model,
    "Gradient Boosting": gb_model,
    "SVM": svm_model
}

results = {}

for name, model in models.items():
    # Train model
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)

    # Evaluate model
    acc = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)

    # Store results
    results[name] = {
        "Accuracy": acc,
        "Classification Report": report
    }

# Step 5: Display results
for model_name, result in results.items():
    print(f"\nModel: {model_name}")
    print(f"Accuracy: {result['Accuracy']:.4f}")
    print(f"Classification Report:\n{result['Classification Report']}")



New Section:
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import string
import re
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

data_fake=pd.read_csv('Fake.csv')
data_true=pd.read_csv('True.csv')
data_fake.head()
data_true.tail()
data_fake["class"]=0
data_true['class']=1

data_fake.shape, data_true.shape
data_fake_manual_testing = data_fake.tail(10)
for i in range(23480,23470,-1):
    data_fake.drop([i],axis = 0, inplace = True)


data_true_manual_testing = data_true.tail(10)
for i in range(21416,21406,-1):
    data_true.drop([i],axis = 0, inplace = True)
data_fake.shape, data_true.shape
data_fake_manual_testing['class']=0
data_true_manual_testing['class']=1
data_fake_manual_testing.head(10)
data_true_manual_testing.head(10)
data_merge=pd.concat([data_fake, data_true], axis = 0)
data_merge.head(10)
data_merge.columns
data=data_merge.drop(['title','subject','date'], axis = 1)
#count of missing values
data.isnull().sum()


Randomly shuffling the dataframe
data = data.sample(frac = 1)

data.head()
data.reset_index(inplace = True)
data.drop(['index'], axis = 1, inplace = True)
data.columns
data.head()


Preprocessing text 
def wordopt(text):
    text = text.lower()
    text = re.sub('\[.*?\]','',text)
    text = re.sub("\\W"," ",text)
    text = re.sub('https?://\S+|www\.\S+','',text)
    text = re.sub('<.*?>+',b'',text)
    text = re.sub('[%s]' % re.escape(string.punctuation),'',text)
    text = re.sub('\w*\d\w*','',text)
    return text

data['text'] = data['text'].apply(wordopt)
x = data['text']
y = data['class']

training the model
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.25)

Extracting Features from the Text Convert text to vectors
from sklearn.feature_extraction.text import TfidfVectorizer

vectorization = TfidfVectorizer()
xv_train = vectorization.fit_transform(x_train)
xv_test = vectorization.transform(x_test)

logistic regression :
from sklearn.linear_model import LogisticRegression
LR = LogisticRegression()
LR.fit(xv_train, y_train)
pred_lr = LR.predict(xv_test)
LR.score(xv_test, y_test)
print (classification_report(y_test, pred_lr))


decision tree classifier:
from sklearn.tree import DecisionTreeClassifier

DT = DecisionTreeClassifier()
DT.fit(xv_train, y_train)

pred_dt = DT.predict(xv_test)
DT.score(xv_test, y_test)
print (classification_report(y_test, pred_lr))

Gradient Boost Classifier
from sklearn.ensemble import GradientBoostingClassifier

GB = GradientBoostingClassifier(random_state = 0)
GB.fit(xv_train, y_train)
pred_gb = GB.predict(xv_test)
GB.score(xv_test, y_test)
print(classification_report(y_test, pred_gb))


Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier

RF = RandomForestClassifier(random_state = 0)
RF.fit(xv_train, y_train)
pred_rf = RF.predict(xv_test)

RF.score(xv_test, y_test)
print (classification_report(y_test, pred_rf))

Testing the Model
def output_lable(n):
    if n==0:
        return "Fake News"
    elif n==1:
        return "Not A Fake News"

def manual_testing(news):
    testing_news = {"text":[news]}
    new_def_test = pd.DataFrame(testing_news)
    new_def_test['text'] = new_def_test["text"].apply(wordopt)
    new_x_test = new_def_test["text"]
    new_xv_test = vectorization.transform(new_x_test)
    pred_LR = LR.predict(new_xv_test)
    pred_DT = DT.predict(new_xv_test)
    pred_GB = GB.predict(new_xv_test)
    pred_RF = RF.predict(new_xv_test)

    return print("\n\nLR Predicition: {} \nDT Prediction: {} \nGBC Prediction: {} \nRFC Prediction:{}".format(output_lable(pred_LR[0]),
                                                                                                             output_lable(pred_DT[0]),
                                                                                                             output_lable(pred_GB[0]),
                                                                                                             output_lable(pred_RF[0])))






















## REAL GPT CODE ##

# import pandas as pd
# import numpy as np
# import re
# import string
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import accuracy_score, classification_report
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.linear_model import LogisticRegression
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
# import nltk
# nltk.download('stopwords')
# from nltk.corpus import stopwords

# # Load datasets
# fake_path = 'data/Fake.csv'
# true_path = 'data/True.csv'

# # Step 1: Load Dataset
# data_fake = pd.read_csv(fake_path)
# data_true = pd.read_csv(true_path)

# # Step 2: Labeling the data
# data_fake["class"] = 0  # Fake news
# data_true["class"] = 1  # Real news

# # Dropping unnecessary rows (last 10 rows for manual testing)
# data_fake_manual_testing = data_fake.tail(10)
# data_true_manual_testing = data_true.tail(10)
# data_fake.drop(data_fake.index[-10:], inplace=True)
# data_true.drop(data_true.index[-10:], inplace=True)

# # Merge and shuffle the datasets
# data_merge = pd.concat([data_fake, data_true], axis=0)
# data_merge = data_merge.sample(frac=1).reset_index(drop=True)

# # Dropping irrelevant columns
# data = data_merge.drop(['title', 'subject', 'date'], axis=1)

# # Check for missing values
# print("Missing values per column:\n", data.isnull().sum())

# # Step 3: Preprocessing the text
# def preprocess_text(text):
#     text = text.lower()
#     text = re.sub(r'\[.*?\]', '', text)
#     text = re.sub(r"https?://\S+|www\.\S+", '', text)
#     text = re.sub(r'<.*?>+', '', text)
#     text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)
#     text = re.sub(r'\w*\d\w*', '', text)
#     return text

# data['text'] = data['text'].apply(preprocess_text)

# # Splitting the data into training and test sets
# X = data['text']
# y = data['class']
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# # Step 4: Text vectorization using TF-IDF
# vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), max_df=0.95, min_df=2)
# X_train_vect = vectorizer.fit_transform(X_train)
# X_test_vect = vectorizer.transform(X_test)

# # Step 5: Model definitions
# models = {
#     "Logistic Regression": LogisticRegression(),
#     "Decision Tree": DecisionTreeClassifier(),
#     "Gradient Boosting": GradientBoostingClassifier(random_state=42),
#     "Random Forest": RandomForestClassifier(random_state=42)
# }

# # Train, predict and evaluate models
# for name, model in models.items():
#     print(f"\nTraining {name}...")
#     model.fit(X_train_vect, y_train)
#     y_pred = model.predict(X_test_vect)

#     print(f"{name} Accuracy: {accuracy_score(y_test, y_pred):.4f}")
#     print(f"Classification Report for {name}:\n")
#     print(classification_report(y_test, y_pred))

# # Manual Testing Function
# def output_label(prediction):
#     return "Fake News" if prediction == 0 else "Real News"

# def manual_testing(news_text):
#     processed_text = preprocess_text(news_text)
#     vectorized_text = vectorizer.transform([processed_text])

#     predictions = {
#         "Logistic Regression": models["Logistic Regression"].predict(vectorized_text),
#         "Decision Tree": models["Decision Tree"].predict(vectorized_text),
#         "Gradient Boosting": models["Gradient Boosting"].predict(vectorized_text),
#         "Random Forest": models["Random Forest"].predict(vectorized_text)
#     }

#     for model_name, prediction in predictions.items():
#         print(f"{model_name} Prediction: {output_label(prediction[0])}")

# # Testing with manual input
# if __name__ == "__main__":
#     # Example input for manual testing
#     test_news = "The government announced new policies today to improve healthcare."
#     manual_testing(test_news)



























## GPT MODIFICATION CODE 3 ##
import pandas as pd
import numpy as np
import re
import string
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
import nltk
import warnings

nltk.download('stopwords')
from nltk.corpus import stopwords

# Suppress specific FutureWarning
warnings.filterwarnings("ignore", category=FutureWarning, module="pandas.core")

# Load datasets
fake_path = 'data/Fake.csv'
true_path = 'data/True.csv'

# Step 1: Load Dataset
data_fake = pd.read_csv(fake_path)
data_true = pd.read_csv(true_path)

# Step 2: Labeling the data
data_fake["class"] = 0  # Fake news
data_true["class"] = 1  # Real news

# Dropping unnecessary rows (last 10 rows for manual testing)
data_fake_manual_testing = data_fake.tail(10)
data_true_manual_testing = data_true.tail(10)
data_fake.drop(data_fake.index[-10:], inplace=True)
data_true.drop(data_true.index[-10:], inplace=True)

# Merge and shuffle the datasets
data_merge = pd.concat([data_fake, data_true], axis=0)
data_merge = data_merge.sample(frac=1).reset_index(drop=True)

# Dropping irrelevant columns
data = data_merge.drop(['title', 'subject', 'date'], axis=1)

# Check for missing values
print("Missing values per column:\n", data.isnull().sum())

# Step 3: Preprocessing the text
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r"https?://\S+|www\.\S+", '', text)
    text = re.sub(r'<.*?>+', '', text)
    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub(r'\w*\d\w*', '', text)
    return text

data['text'] = data['text'].apply(preprocess_text)

# Splitting the data into training and test sets
X = data['text']
y = data['class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Step 4: Text vectorization using TF-IDF
vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), max_df=0.95, min_df=2)
X_train_vect = vectorizer.fit_transform(X_train)
X_test_vect = vectorizer.transform(X_test)

# Step 5: Model definitions
models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42)
}

# Initialize a dataframe to store metrics
metrics_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision (Class 0)', 'Recall (Class 0)', 'F1-Score (Class 0)',
                                   'Precision (Class 1)', 'Recall (Class 1)', 'F1-Score (Class 1)'])

# Train, predict and evaluate models
for name, model in models.items():
    print(f"\nTraining {name}...")
    model.fit(X_train_vect, y_train)
    y_pred = model.predict(X_test_vect)

    acc = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)

    new_row = pd.DataFrame([{
        'Model': name,
        'Accuracy': acc,
        'Precision (Class 0)': report['0']['precision'],
        'Recall (Class 0)': report['0']['recall'],
        'F1-Score (Class 0)': report['0']['f1-score'],
        'Precision (Class 1)': report.get('1', {}).get('precision', np.nan),
        'Recall (Class 1)': report.get('1', {}).get('recall', np.nan),
        'F1-Score (Class 1)': report.get('1', {}).get('f1-score', np.nan)
    }])

    metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)

# Display the metrics in a tabular format
print("\nModel Performance Summary:")
print(metrics_df)

# Plotting the accuracy comparison with three decimal places
plt.figure(figsize=(10, 6))
barplot = sns.barplot(x='Accuracy', y='Model', data=metrics_df, palette='viridis')
plt.title('Model Accuracy Comparison')
plt.xlabel('Accuracy')
plt.ylabel('Model')
plt.xlim(0.95, 1.0)

# Adding accuracy values to the bars
for p in barplot.patches:
    barplot.annotate(format(p.get_width(), '.3f'), 
                     (p.get_width(), p.get_y() + p.get_height() / 2), 
                     ha='left', va='center', 
                     xytext=(5, 0), 
                     textcoords='offset points')

plt.show()

# Manual Testing Function
def output_label(prediction):
    return "Fake News" if prediction == 0 else "Real News"

def manual_testing(news_text):
    processed_text = preprocess_text(news_text)
    vectorized_text = vectorizer.transform([processed_text])

    predictions = {name: model.predict(vectorized_text)[0] for name, model in models.items()}

    print("\nManual Testing Results:")
    for model_name, prediction in predictions.items():
        print(f"{model_name} Prediction: {output_label(prediction)}")

# Testing with manual input
if __name__ == "__main__":
    # Taking user input for manual testing
    user_input = input("\nEnter the news text for evaluation: ")
    manual_testing(user_input)













































## GPT MODIFICATION CODE 1 ##
## NLTK USED HERE ##

import pandas as pd
import numpy as np
import re
import string
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from collections import Counter
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

# Load datasets
fake_path = 'data/Fake.csv'
true_path = 'data/True.csv'

data_fake = pd.read_csv(fake_path).drop_duplicates()
data_true = pd.read_csv(true_path).drop_duplicates()

data_fake["class"] = 0  # Fake news
data_true["class"] = 1  # Real news

data_fake.drop(data_fake.index[-10:], inplace=True)
data_true.drop(data_true.index[-10:], inplace=True)

data_merge = pd.concat([data_fake, data_true], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)
data = data_merge.drop(['title', 'subject', 'date'], axis=1).dropna()

# Text preprocessing
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r"https?://\S+|www\.\S+", '', text)
    text = re.sub(r'<.*?>+', '', text)
    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub(r'\w*\d\w*', '', text)
    tokens = word_tokenize(text)
    return ' '.join([lemmatizer.lemmatize(word) for word in tokens if word not in stopwords.words('english')])

data['text'] = data['text'].apply(preprocess_text)

# Train-test split
X = data['text']
y = data['class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), max_df=0.95, min_df=2, ngram_range=(1, 2), sublinear_tf=True)
X_train_vect = vectorizer.fit_transform(X_train)
X_test_vect = vectorizer.transform(X_test)

# Model definitions
models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42)
}

# Cross-validation and training
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for name, model in models.items():
    scores = cross_val_score(model, X_train_vect, y_train, cv=cv, scoring='accuracy')
    print(f"\n{name} Cross-Validation Accuracy: {scores.mean():.4f} ± {scores.std():.4f}")
    model.fit(X_train_vect, y_train)
    joblib.dump(model, f"models/{name}.pkl")

# Model evaluation
def evaluate_model(name, model):
    y_pred = model.predict(X_test_vect)
    print(f"\n{name} Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print(f"Classification Report for {name}:\n", classification_report(y_test, y_pred))
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(f'Confusion Matrix - {name}')
    plt.show()

# Load models and evaluate
test_models = {name: joblib.load(f"models/{name}.pkl") for name in models.keys()}
for name, model in test_models.items():
    evaluate_model(name, model)

# Manual Testing with Majority Voting
def output_label(prediction):
    return "Fake News" if prediction == 0 else "Real News"

def manual_testing(news_text):
    processed_text = preprocess_text(news_text)
    vectorized_text = vectorizer.transform([processed_text])
    predictions = {name: model.predict(vectorized_text)[0] for name, model in test_models.items()}
    majority_vote = Counter(predictions.values()).most_common(1)[0][0]
    print("\nModel Predictions:")
    for model_name, pred in predictions.items():
        print(f"{model_name}: {output_label(pred)}")
    print("\nFinal Prediction (Majority Vote):", output_label(majority_vote))

if __name__ == "__main__":
    test_news = "The government announced new policies today to improve healthcare."
    manual_testing(test_news)



































## GPT MODIFICATION CODE 2 ##
## SPACY USED HERE ##

import pandas as pd
import numpy as np
import re
import string
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from collections import Counter
import spacy
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

# Load datasets
fake_path = 'data/Fake.csv'
true_path = 'data/True.csv'

data_fake = pd.read_csv(fake_path).drop_duplicates()
data_true = pd.read_csv(true_path).drop_duplicates()

data_fake["class"] = 0  # Fake news
data_true["class"] = 1  # Real news

data_fake.drop(data_fake.index[-10:], inplace=True)
data_true.drop(data_true.index[-10:], inplace=True)

data_merge = pd.concat([data_fake, data_true], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)
data = data_merge.drop(['title', 'subject', 'date'], axis=1).dropna()

# Text preprocessing using spaCy
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\[.*?\]', '', text)  # Remove text inside brackets
    text = re.sub(r"https?://\S+|www\.\S+", '', text)  # Remove URLs
    text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags
    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation
    text = re.sub(r'\w*\d\w*', '', text)  # Remove words with numbers
    
    # Tokenization & Lemmatization using spaCy
    doc = nlp(text)
    tokens = [token.lemma_ for token in doc if not token.is_stop]
    
    return ' '.join(tokens)

data['text'] = data['text'].apply(preprocess_text)

# Train-test split
X = data['text']
y = data['class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, ngram_range=(1, 2), sublinear_tf=True)
X_train_vect = vectorizer.fit_transform(X_train)
X_test_vect = vectorizer.transform(X_test)

# Model definitions
models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42)
}

# Cross-validation and training
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for name, model in models.items():
    scores = cross_val_score(model, X_train_vect, y_train, cv=cv, scoring='accuracy')
    print(f"\n{name} Cross-Validation Accuracy: {scores.mean():.4f} ± {scores.std():.4f}")
    model.fit(X_train_vect, y_train)
    joblib.dump(model, f"models/{name}.pkl")

# Model evaluation
def evaluate_model(name, model):
    y_pred = model.predict(X_test_vect)
    print(f"\n{name} Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print(f"Classification Report for {name}:\n", classification_report(y_test, y_pred))
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(f'Confusion Matrix - {name}')
    plt.show()

# Load models and evaluate
test_models = {name: joblib.load(f"models/{name}.pkl") for name in models.keys()}
for name, model in test_models.items():
    evaluate_model(name, model)

# Manual Testing with Majority Voting
def output_label(prediction):
    return "Fake News" if prediction == 0 else "Real News"

def manual_testing(news_text):
    processed_text = preprocess_text(news_text)
    vectorized_text = vectorizer.transform([processed_text])
    predictions = {name: model.predict(vectorized_text)[0] for name, model in test_models.items()}
    majority_vote = Counter(predictions.values()).most_common(1)[0][0]
    print("\nModel Predictions:")
    for model_name, pred in predictions.items():
        print(f"{model_name}: {output_label(pred)}")
    print("\nFinal Prediction (Majority Vote):", output_label(majority_vote))

if __name__ == "__main__":
    test_news = "The government announced new policies today to improve healthcare."
    manual_testing(test_news)